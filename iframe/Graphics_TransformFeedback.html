<!-- N.B. All single quote strings starting with '@' and are in all caps denote placeholders for replacement code  -->
<html>
    <head>
        <link rel="stylesheet" href="./example.css">
        <title>Graphics: TransformFeedback</title>
        <!-- no es5libs -->
    </head>
    <body>
        <div id="app">
            <div id="appInner">
                <!--A link without href, which makes it invisible. Setting href in an example would trigger a download when clicked.-->
                
                <canvas id="application-canvas"></canvas>
            </div>
        </div>
        <script src='./playcanvas-observer.js'></script>
        <script src='./pathes.js'></script>
        <script></script>
        <script></script>
        <script>async function example({ canvas, deviceType, glslangPath, twgslPath, files, assetPath }) {
    const gfxOptions = {
        deviceTypes: [deviceType],
        glslangUrl: glslangPath + 'glslang.js',
        twgslUrl: twgslPath + 'twgsl.js'
    };

    const device = await pc.createGraphicsDevice(canvas, gfxOptions);
    const createOptions = new pc.AppOptions();
    createOptions.graphicsDevice = device;

    createOptions.componentSystems = [
        pc.RenderComponentSystem,
        pc.CameraComponentSystem,
        pc.LightComponentSystem,
    ];
    createOptions.resourceHandlers = [
        pc.TextureHandler,
        pc.ContainerHandler
    ];

    const app = new pc.AppBase(canvas);
    app.init(createOptions);

    const assets = {
        'statue': new pc.Asset('statue', 'container', { url: assetPath + 'models/statue.glb' })
    };

    const assetListLoader = new pc.AssetListLoader(Object.values(assets), app.assets);
    assetListLoader.load(() => {
        app.start();

        // Set the canvas to fill the window and automatically change resolution to be the same as the canvas size
        app.setCanvasFillMode(pc.FILLMODE_FILL_WINDOW);
        app.setCanvasResolution(pc.RESOLUTION_AUTO);

        // Ensure canvas is resized when window changes size
        const resize = () => app.resizeCanvas();
        window.addEventListener('resize', resize);
        app.on('destroy', () => {
            window.removeEventListener('resize', resize);
        });

        app.scene.ambientLight = new pc.Color(0.2, 0.2, 0.2);

        // create small 2D texture representing movement direction (wind)
        const textureResolution = 10;
        const textureData = new Uint8ClampedArray(textureResolution * textureResolution * 4);

        for (let i = 0; i < textureResolution * textureResolution; i++) {

            // rgb store biased movement direction
            textureData[i * 4] = 127 + Math.random() * 50 - 25;
            textureData[i * 4 + 1] = 127 + Math.random() * 50 - 25;
            textureData[i * 4 + 2] = 127 + Math.random() * 50 - 25;

            // set alpha to 255 for debugging purposes
            textureData[i * 4 + 3] = 255;
        }

        // create texture
        const texture = new pc.Texture(app.graphicsDevice, {
            width: textureResolution,
            height: textureResolution,
            format: pc.PIXELFORMAT_RGBA8,
            cubemap: false,
            mipmaps: false,
            minFilter: pc.FILTER_LINEAR,
            magFilter: pc.FILTER_LINEAR,
            addressU: pc.ADDRESS_CLAMP_TO_EDGE,
            addressV: pc.ADDRESS_CLAMP_TO_EDGE
        });

        // initialize it with data
        const pixels = texture.lock();
        pixels.set(textureData);
        texture.unlock();

        // Create main camera, which renders the world
        const camera = new pc.Entity();
        camera.addComponent("camera", {
            clearColor: new pc.Color(0.1, 0.1, 0.1)
        });
        app.root.addChild(camera);

        // set up texture transform part, on webgl2 devices only
        let tf;
        let shader;
        const areaSize = 30;

        // resolve parameters to simulation shader parameters
        const areaSizeUniform = app.graphicsDevice.scope.resolve("areaSize");
        const deltaTimeUniform = app.graphicsDevice.scope.resolve("deltaTime");
        const directionSampler = app.graphicsDevice.scope.resolve("directionSampler");

        // @ts-ignore engine-tsd
        if (app.graphicsDevice.isWebGL2) {

            // simulated particles
            const maxNumPoints = 200000;
            const positions = new Float32Array(4 * maxNumPoints);

            // generate random data, these are used as seeds to generate particles in vertex shader
            for (let i = 0; i < maxNumPoints; i++) {
                positions[i * 4] = Math.random();
                positions[i * 4 + 1] = Math.random();
                positions[i * 4 + 2] = Math.random();

                // set life time to 0 which triggers particle restart in shader
                positions[i * 4 + 3] = 0;
            }

            // store these in a vertex buffer of a mesh
            const mesh = new pc.Mesh(app.graphicsDevice);
            mesh.setPositions(positions, 4);
            mesh.update(pc.PRIMITIVE_POINTS, false);

            // set large bounding box so we don't need to update it each frame
            mesh.aabb = new pc.BoundingBox(new pc.Vec3(0, 0, 0), new pc.Vec3(100, 100, 100));

            // Create the shader from the vertex and fragment shaders which is used to render point sprites
            shader = new pc.Shader(app.graphicsDevice, {
                attributes: { aPosition: pc.SEMANTIC_POSITION },
                vshader: files['shaderCloud.vert'],
                fshader: files['shaderCloud.frag']
            });

            // Create a new material with the new shader and additive alpha blending
            const material = new pc.Material();
            material.shader = shader;
            material.blendType = pc.BLEND_ADDITIVEALPHA;
            material.depthWrite = false;

            // Create the mesh instance
            const meshInstance = new pc.MeshInstance(mesh, material);

            // create an entity used to render the mesh instance using a render component
            const entity = new pc.Entity();
            entity.addComponent("render", {
                type: 'asset',
                meshInstances: [meshInstance]
            });
            app.root.addChild(entity);

            // set up transform feedback. This creates a clone of the vertex buffer, and sets up rendering to ping pong between them
            tf = new pc.TransformFeedback(mesh.vertexBuffer);
            shader = pc.TransformFeedback.createShader(app.graphicsDevice, files['shaderFeedback.vert'], "transformShaderExample");
        }

        // update things each frame
        let time = 0;
        app.on("update", function (dt) {

            // rotate camera around
            time += dt;
            camera.setLocalPosition(9 * Math.sin(time * 0.2), 6, 25 * Math.cos(time * 0.2));
            camera.lookAt(new pc.Vec3(0, 3, 0));

            // if transform feedback was initialized
            if (tf) {

                // set up simulation parameters
                areaSizeUniform.setValue(areaSize);
                deltaTimeUniform.setValue(dt);
                directionSampler.setValue(texture);

                // execute simulation
                tf.process(shader);
            }
        });
    });
    return app;
}</script>
        <script>
            const ENGINE_PATH = "../src/index.js";
            const NODE_ENV = "development";

            /**
             * Used in outline and posteffects to make ES5 scripts work in ES6
             * @example
             * // doesn't start with 'class', so not changing any behaviour
             * debugger; // step through with F11 to debug
             * Object.prototype.toString.call(1) === '[object Number]'
             */
            function enablePolyfillFunctionCall() {
                const functionCall = Function.prototype.call;
                function polyCall(thisArg, ...args) {
                    if (this.toString().startsWith('class')) {
                        return Object.assign(thisArg, new this(...args));
                    }
                    return functionCall.bind(this)(thisArg, ...args);
                }
                Function.prototype.call = polyCall;
            }
            enablePolyfillFunctionCall();

            /**
             * Can load UMD and ESM. UMD registers itself into globalThis, while ESM is handled
             * to specifically to do the same, so we achieve the same result, no matter which
             * target build/src we linked to.
             */
            async function loadScript(name, src) {
                // console.log('loadScript>', { name, src });
                const module = await import(src);
                const isESM = Object.keys(module).length;
                if (isESM) {
                    window[name] = module;
                }
            }

            /**
             * @returns {string}
             */
            function getDeviceType() {
                if (false) {
                    return 'webgpu';
                }

                const last = localStorage.getItem('preferredGraphicsDevice');
                if (last !== null) {
                    if (last === 'webgpu' && !false) {
                        console.warn('Picked WebGPU but example is not supported on WebGPU, defaulting to WebGL2');
                        return 'webgl2';
                    }
                    return last;
                } else if (false) {
                    let preferredDevice = 'webgpu';
                    // Lack of Chrome's WebGPU support on Linux
                    if (navigator.platform.includes('Linux') && navigator.appVersion.includes("Chrome")) {
                        preferredDevice = 'webgl2';
                    }
                    return window.top.preferredGraphicsDevice || preferredDevice;
                } else if (['webgl1', 'webgl2'].includes(window.top.preferredGraphicsDevice)) {
                    return window.top.preferredGraphicsDevice;
                } else {
                    return 'webgl2';
                }
            }

            /**
             * Get the specified engine, picking the right choice from three sources:
             *  - Example#ENGINE (lowest priority)
             *  - NODE_ENV (2nd lowest priority)
             *  - ENGINE_PATH (highest priority)
             * If none of these sources are given, we simply pick build/playcanvas.js (ES5)
             */
            function getSpecifiedEngine() {
                let specifiedEngine = "./playcanvas.js";
                if (NODE_ENV === 'development') {
                    specifiedEngine = "./playcanvas.dbg.js";
                }
                if (ENGINE_PATH.length) {
                    const entryPoint = ENGINE_PATH.split('/').pop();
                    specifiedEngine = './ENGINE_PATH/' + entryPoint;
                }
                return specifiedEngine;
            }

            function getQueryParameters() {
                return Object.fromEntries(
                    window.top.location.href.split('?').pop().split('#')[0].split('&').map(_ => _.split('='))
                );
            }

            let app;
            let ready = false; // Used in indicate if UI can render Controls
            let started = false;
            let miniStats;
            let allowRestart = 'true';
            const args = getQueryParameters();
            let data = new observer.Observer({});
            /**
             * Keep it function in first run for nicer debug locations.
             * @type {Record<string, string | Function>}
             */
            const files = {};
            files['example.mjs'] = example.toString();
            if (window.controls) {
                files['controls.mjs'] = controls.toString();
            }
            var filesObject = {"shaderFeedback.vert":"\n// vertex shader used to move particles during transform-feedback simulation step\n\n// input and output is vec4, containing position in .xyz and lifetime in .w\nattribute vec4 vertex_position;\nvarying vec4 out_vertex_position;\n\n// parameters controlling simulation\nuniform float deltaTime;\nuniform float areaSize;\n\n// texture storing random direction vectors\nuniform sampler2D directionSampler;\n\n// function returning random number based on vec2 seed parameter\nfloat rand(vec2 co) {\n    return fract(sin(dot(co.xy ,vec2(12.9898,78.233))) * 43758.5453);\n}\n\nvoid main(void) {\n\n    // texture contains direction of particle movement - read it based on particle's position\n    vec2 texCoord = vertex_position.xz / areaSize + 0.5;\n    vec3 dir = texture2D(directionSampler, texCoord).xyz;\n    dir = dir * 2.0 - 1.0;\n\n    // move particle along direction with some speed\n    float speed = 20.0 * deltaTime;\n    vec3 pos = vertex_position.xyz + dir * speed;\n\n    // age the particle\n    float liveTime = vertex_position.w;\n    liveTime -= deltaTime;\n\n    // if particle is too old, regenerate it\n    if (liveTime <= 0.0) {\n\n        // random life time\n        liveTime = rand(pos.xy) * 2.0;\n\n        // random position\n        pos.x = rand(pos.xz) * areaSize - 0.5 * areaSize;\n        pos.y = rand(pos.xy) * 4.0;\n        pos.z = rand(pos.yz) * areaSize - 0.5 * areaSize;\n    }\n\n    // write out updated particle\n    out_vertex_position = vec4(pos, liveTime);\n}","shaderCloud.vert":"\n// vertex shader used to render point sprite particles\n\n// Attributes per vertex: position\nattribute vec4 aPosition;\n\nuniform mat4   matrix_viewProjection;\n\n// Color to fragment program\nvarying vec4 outColor;\n\nvoid main(void)\n{\n    // Transform the geometry (ignore life time which is stored in .w of position)\n    vec4 worldPosition = vec4(aPosition.xyz, 1);\n    gl_Position = matrix_viewProjection * worldPosition;\n\n    // point sprite size\n    gl_PointSize = 2.0;\n\n    // color depends on position of particle\n    outColor = vec4(worldPosition.y * 0.25, 0.1, worldPosition.z * 0.2, 1);\n}","shaderCloud.frag":"\n// fragment shader used to render point sprite particles\nprecision mediump float;\nvarying vec4 outColor;\n\nvoid main(void)\n{\n    // color supplied by vertex shader\n    gl_FragColor = outColor;\n}"};
            function resolveFunction(_) {
                if (_.call) {
                    return _;
                }
                return new Function('return ' + _)();
            }
            Object.assign(files, filesObject);
            function requestFiles() {
                const responseEvent = new CustomEvent("requestedFiles", { detail: files });
                window.top.dispatchEvent(responseEvent);
            }
            /**
             * This function is called from React whenever we click on MiniStats icon,
             * even PlayCanvas' pc itself could be undefined here.
             */
            function showStats() {
                // examples/misc/mini-stats.mjs creates its own instance of ministats, prevent two mini-stats here
                if (false) {
                    return;
                }
                if (typeof pc === 'undefined' || typeof pcx === 'undefined') {
                    return;
                }
                const deviceType = app?.graphicsDevice?.deviceType;
                if (!deviceType || deviceType === 'null') {
                    return;
                }
                if (args.miniStats === 'false') {
                    return;
                }
                if (!miniStats) {
                    miniStats = new pcx.MiniStats(app);
                }
                miniStats.enabled = true;
            }
            function hideStats() {
                if (!miniStats) {
                    return;
                }
                miniStats.enabled = false;
            }
            /**
             * This function is called from React whenever we change an example in any possible state,
             * even PlayCanvas' pc itself could be undefined here.
             */
            function destroy() {
                miniStats?.destroy();
                miniStats = null;
                // Can't call app.destroy() twice without an error,
                // so we check for app.graphicsDevice first
                if (app && app.graphicsDevice) {
                    app.destroy();
                }
                ready = false;
            }
            function hotReload() {
                if (!allowRestart) {
                    console.warn('hotReload> Dropping restart while still restarting');
                    return;
                }
                destroy();
                data = new observer.Observer({});
                main(files);
            }
            window.addEventListener('requestFiles', requestFiles);
            window.addEventListener('showStats', showStats);
            window.addEventListener('hideStats', hideStats);
            window.addEventListener('hotReload', hotReload);
            window.addEventListener('destroy', destroy);

            function updateControls() {
                const event = new CustomEvent("updateFiles", {
                    detail: {
                        files
                    }
                });
                window.top.dispatchEvent(event);
            }
            function updateActiveDevice() {
                const event = new CustomEvent("updateActiveDevice", {
                    detail: app.graphicsDevice.deviceType
                });
                window.top.dispatchEvent(event);
            }

            async function main(files) {
                allowRestart = false;
                await loadScript('pc', getSpecifiedEngine());
                await loadScript('pcx', './playcanvas-extras.js');

                window.top.pc = pc;
                const canvas = document.getElementById("application-canvas");

                window.top.observerData = data;
                const deviceType = getDeviceType();

                if (args.deviceType) {
                    console.warn("overwriting default deviceType from URL");
                    deviceType = args.deviceType;
                }
                if (!deviceType) {
                    console.warn("No deviceType given, defaulting to WebGL2");
                    deviceType = 'webgl2';
                }

                if (!started) {
                    // just notify to clean UI, but not during hot-reload
                    const event = new CustomEvent("exampleLoading", {
                        detail: {
                            showDeviceSelector: true,
                        }
                    });
                    window.top.dispatchEvent(event);
                }

                const example = resolveFunction(files['example.mjs']);
                files['example.mjs'] = files['example.mjs'].toString();
                app = await example({
                    canvas,
                    deviceType,
                    data,
                    assetPath,
                    scriptsPath,
                    ammoPath,
                    basisPath,
                    dracoPath,
                    glslangPath,
                    twgslPath,
                    pcx,
                    files,
                });
                ready = true;

                class ExampleLoadEvent extends CustomEvent {
                    constructor(deviceType) {
                        super("exampleLoad");
                        this.files = files;
                        this.description = "";
                    }
                }

                const startHandler = () => {
                    if (app.graphicsDevice?.canvas) {
                        showStats();
                        if (!started) { // only one time, recalls of main() are caused by Monaco live coding
                            window.top.dispatchEvent(new ExampleLoadEvent());
                        }
                        started = true;
                        updateControls();
                        updateActiveDevice();
                        allowRestart = true;
                    } else {
                        console.warn('main> no canvas');
                    }
                };

                // Wait until example has called app.start()
                // And if it already called start, we will know by app.frame > 0
                // app.start() is called when assets loaded in examples
                if (app) {
                    if (app.frame) { // app already started
                        startHandler();
                    } else { // Wait for app.start()
                        app.once('start', startHandler);
                    }
                } else {
                    // The example function didn't return an app instance
                    // still update the UI and assume it has started.
                    window.top.dispatchEvent(new ExampleLoadEvent());
                    started = true;
                    updateControls();
                    allowRestart = true;
                }
            }
            window.onload = () => main(files);
        </script>
    </body>
</html>
