<html>
    <head>
        <link rel="stylesheet" href="./example.css">
        <title>Graphics: ReflectionBox</title>
        <!-- no es5libs -->
    </head>
    <body>
        <div id="app">
            <div id="appInner">
                <!--A link without href, which makes it invisible. Setting href in an example would trigger a download when clicked.-->
                <div style="width:100%; position:absolute; top:10px">
                    <div style="text-align: center;">
                        <a id="ar-link" rel="ar" download="asset.usdz">
                            <img src="./arkit.png" id="button" width="200"/>
                        </a>    
                    </div>
                </div>
                <canvas id='application-canvas'></canvas>
            </div>
        </div>
        <script src='./playcanvas-observer.js'></script>
        <script src='./pathes.js'></script>
        <!-- imports (if any) -->
        <script>

        </script>
        <!-- controls (if given) -->
        <script>
function controls({ observer, ReactPCUI, React, jsx, fragment }) {
    const { BindingTwoWay, LabelGroup, Panel, SelectInput, SliderInput } = ReactPCUI;
    return fragment(
        jsx(Panel, { headerText: 'Settings' },
            jsx(LabelGroup, { text: 'Update' },
                jsx(SelectInput, {
                    binding: new BindingTwoWay(),
                    link: { observer, path: 'settings.updateFrequency' },
                    type: "number",
                    options: [
                        { v: 0, t: 'Once' },
                        { v: 1, t: 'Every frame' },
                        { v: 10, t: 'Every 10 frames' },
                        { v: 30, t: 'Every 30 frames' }
                    ]
                })),
            jsx(LabelGroup, { text: 'Gloss' },
                jsx(SliderInput, {
                    binding: new BindingTwoWay(),
                    link: { observer, path: 'settings.gloss' },
                    min: 0,
                    max: 1,
                    precision: 2
                })),
            jsx(LabelGroup, { text: 'Metalness' },
                jsx(SliderInput, {
                    binding: new BindingTwoWay(),
                    link: { observer, path: 'settings.metalness' },
                    min: 0,
                    max: 1,
                    precision: 2
                })),
            jsx(LabelGroup, { text: 'Reflectivity' },
                jsx(SliderInput, {
                    binding: new BindingTwoWay(),
                    link: { observer, path: 'settings.reflectivity' },
                    min: 0,
                    max: 1,
                    precision: 2
                })),
            jsx(LabelGroup, { text: 'Bumpiness' },
                jsx(SliderInput, {
                    binding: new BindingTwoWay(),
                    link: { observer, path: 'settings.bumpiness' },
                    min: 0,
                    max: 1,
                    precision: 2
                })
            )
        )
    );
}
        </script>
        <script>
async function example({ canvas, deviceType, data, assetPath, scriptsPath, glslangPath, twgslPath }) {

    const assets = {
        'script1': new pc.Asset('script', 'script', { url: scriptsPath + 'camera/orbit-camera.js' }),
        'script2': new pc.Asset('script', 'script', { url: scriptsPath + 'utils/cubemap-renderer.js' }),
        'normal': new pc.Asset('normal', 'texture', { url: assetPath + 'textures/normal-map.png' })
    };

    const gfxOptions = {
        deviceTypes: [deviceType],
        glslangUrl: glslangPath + 'glslang.js',
        twgslUrl: twgslPath + 'twgsl.js'
    };

    const device = await pc.createGraphicsDevice(canvas, gfxOptions);
    const createOptions = new pc.AppOptions();
    createOptions.graphicsDevice = device;
    createOptions.mouse = new pc.Mouse(document.body);
    createOptions.touch = new pc.TouchDevice(document.body);

    createOptions.componentSystems = [
        // @ts-ignore
        pc.RenderComponentSystem,
        // @ts-ignore
        pc.CameraComponentSystem,
        // @ts-ignore
        pc.LightComponentSystem,
        // @ts-ignore
        pc.ScriptComponentSystem
    ];
    createOptions.resourceHandlers = [
        // @ts-ignore
        pc.ScriptHandler,
        // @ts-ignore
        pc.TextureHandler,
        // @ts-ignore
        pc.ContainerHandler
    ];

    const app = new pc.AppBase(canvas);
    app.init(createOptions);

    // Set the canvas to fill the window and automatically change resolution to be the same as the canvas size
    app.setCanvasFillMode(pc.FILLMODE_FILL_WINDOW);
    app.setCanvasResolution(pc.RESOLUTION_AUTO);

    // Ensure canvas is resized when window changes size
    const resize = () => app.resizeCanvas();
    window.addEventListener('resize', resize);
    app.on('destroy', () => {
        window.removeEventListener('resize', resize);
    });

    const assetListLoader = new pc.AssetListLoader(Object.values(assets), app.assets);
    assetListLoader.load(() => {

        app.start();

        data.set('settings', {
            updateFrequency: 10,
            gloss: 0.8,
            metalness: 0.9,
            bumpiness: 0.2,
            reflectivity: 0.5
        });

        // get existing layers
        const worldLayer = app.scene.layers.getLayerByName("World");
        const uiLayer = app.scene.layers.getLayerByName("UI");

        // create a layer for object that do not render into reflection cubemap
        const excludedLayer = new pc.Layer({ name: "Excluded" });
        app.scene.layers.insert(excludedLayer, app.scene.layers.getTransparentIndex(worldLayer) + 1);

        // create an envAtlas texture, which will hold a prefiltered lighting generated from the cubemap.
        // This represents a reflection prefiltered for different levels of roughness
        const envAtlas = new pc.Texture(app.graphicsDevice, {
            width: 512,
            height: 512,
            format: pc.PIXELFORMAT_RGBA8,
            type: pc.TEXTURETYPE_RGBM,
            projection: pc.TEXTUREPROJECTION_EQUIRECT,
            addressU: pc.ADDRESS_CLAMP_TO_EDGE,
            addressV: pc.ADDRESS_CLAMP_TO_EDGE,
            mipmaps: false
        });

        // material for the walls
        const roomMaterial = new pc.StandardMaterial();
        roomMaterial.useMetalness = true;
        roomMaterial.diffuse = pc.Color.WHITE;
        roomMaterial.normalMap = assets.normal.resource;
        roomMaterial.normalMapTiling.set(5, 5);
        roomMaterial.bumpiness = 0.1;
        roomMaterial.gloss = 0.9;
        roomMaterial.reflectivity = 0.3;
        // @ts-ignore
        roomMaterial.envAtlas = envAtlas; // use reflection from env atlas
        roomMaterial.metalness = 0.5;

        // the material uses box projected cubemap for reflections. Set its bounding box the the size of the room
        // so that the reflections line up
        roomMaterial.cubeMapProjection = pc.CUBEPROJ_BOX;
        roomMaterial.cubeMapProjectionBox = new pc.BoundingBox(new pc.Vec3(0, 200, 0), new pc.Vec3(400, 200, 400));
        roomMaterial.update();

        // material for the magenta emissive beams
        const emissiveMaterial = new pc.StandardMaterial();
        emissiveMaterial.emissive = pc.Color.MAGENTA;
        emissiveMaterial.diffuse = pc.Color.BLACK;
        emissiveMaterial.update();

        // material for the white sphere representing an omni light
        const lightMaterial = new pc.StandardMaterial();
        lightMaterial.emissive = pc.Color.WHITE;
        lightMaterial.diffuse = pc.Color.BLACK;
        lightMaterial.update();

        // material for the reflective sphere in the center
        const sphereMaterial = new pc.StandardMaterial();
        sphereMaterial.useMetalness = true;
        sphereMaterial.diffuse = pc.Color.WHITE;
        sphereMaterial.normalMap = assets.normal.resource;
        sphereMaterial.normalMapTiling.set(5, 5);
        sphereMaterial.bumpiness = 0.7;
        sphereMaterial.gloss = 0.3;
        sphereMaterial.metalness = 0.7;
        sphereMaterial.reflectivity = 0.3;
        // @ts-ignore
        sphereMaterial.envAtlas = envAtlas; // use reflection from env atlas
        sphereMaterial.update();
        /** @type {pc.Texture} */
        let videoTexture;
        if (!app.graphicsDevice.isWebGPU) {
            // set up video playback into a texture
            videoTexture = new pc.Texture(app.graphicsDevice, {
                format: pc.PIXELFORMAT_RGB565,
                mipmaps: false,
                minFilter: pc.FILTER_LINEAR,
                magFilter: pc.FILTER_LINEAR,
                addressU: pc.ADDRESS_CLAMP_TO_EDGE,
                addressV: pc.ADDRESS_CLAMP_TO_EDGE
            });

            // create a HTML element with the video
            /** @type {HTMLVideoElement} */
            const video = document.createElement('video');
            video.id = 'vid';
            video.loop = true;
            video.muted = true;
            video.autoplay = true;
            video.playsInline = true;
            video.crossOrigin = "anonymous";
            video.setAttribute('style', 'display: block; width: 1px; height: 1px; position: absolute; opacity: 0; z-index: -1000; top: 0px; pointer-events: none');
            video.src = assetPath + 'video/SampleVideo_1280x720_1mb.mp4';
            document.body.append(video);
            video.addEventListener('canplaythrough', function () {
                videoTexture.setSource(video);
            });
        }

        // materials used on the TV screen to display the video texture
        const screenMaterial = new pc.StandardMaterial();
        screenMaterial.useLighting = false;
        screenMaterial.emissiveMap = videoTexture;
        screenMaterial.update();

        /**
         * helper function to create a 3d primitive including its material
         * @param {string} primitiveType 
         * @param {pc.Vec3} position 
         * @param {pc.Vec3} scale 
         * @param {pc.Material} material 
         */
        function createPrimitive(primitiveType, position, scale, material) {
            // create the primitive using the material
            const primitive = new pc.Entity();
            primitive.addComponent('render', {
                type: primitiveType,
                material: material,
                layers: [worldLayer.id, excludedLayer.id],
                castShadows: false,
                receiveShadows: false
            });

            // set position and scale and add it to scene
            primitive.setLocalPosition(position);
            primitive.setLocalScale(scale);
            app.root.addChild(primitive);
        }

        // create the ground plane from the boxes
        createPrimitive("box", new pc.Vec3(0, 0, 0), new pc.Vec3(800, 2, 800), roomMaterial);
        createPrimitive("box", new pc.Vec3(0, 400, 0), new pc.Vec3(800, 2, 800), roomMaterial);

        // walls
        createPrimitive("box", new pc.Vec3(400, 200, 0), new pc.Vec3(2, 400, 800), roomMaterial);
        createPrimitive("box", new pc.Vec3(-400, 200, 0), new pc.Vec3(2, 400, 800), roomMaterial);
        createPrimitive("box", new pc.Vec3(0, 200, -400), new pc.Vec3(800, 400, 0), roomMaterial);
        createPrimitive("box", new pc.Vec3(0, 200, 400), new pc.Vec3(800, 400, 0), roomMaterial);

        // emissive pillars
        createPrimitive("box", new pc.Vec3(400, 200, -50), new pc.Vec3(20, 400, 20), emissiveMaterial);
        createPrimitive("box", new pc.Vec3(400, 200, 50), new pc.Vec3(20, 400, 20), emissiveMaterial);
        createPrimitive("box", new pc.Vec3(-400, 200, 50), new pc.Vec3(20, 400, 20), emissiveMaterial);
        createPrimitive("box", new pc.Vec3(-400, 200, -50), new pc.Vec3(20, 400, 20), emissiveMaterial);
        createPrimitive("box", new pc.Vec3(0, 400, 50), new pc.Vec3(800, 20, 20), emissiveMaterial);
        createPrimitive("box", new pc.Vec3(0, 400, -50), new pc.Vec3(800, 20, 20), emissiveMaterial);

        // screen
        createPrimitive("box", new pc.Vec3(0, 200, 400), new pc.Vec3(500, 250, 5), screenMaterial);

        // shiny sphere
        const sphereEntity = new pc.Entity();
        sphereEntity.addComponent("render", {
            type: "sphere",
            material: sphereMaterial,
            castShadows: false,
            receiveShadows: false
        });
        sphereEntity.setLocalScale(300, 300, 300);
        sphereEntity.setLocalPosition(0, 150, 0);
        app.root.addChild(sphereEntity);

        // create an omni light white orbits the room to avoid it being completely dark
        const lightOmni = new pc.Entity();
        lightOmni.addComponent("light", {
            type: "omni",
            layers: [excludedLayer.id], // add it to excluded layer, we don't want the light captured in the reflection
            castShadows: false,
            color: pc.Color.WHITE,
            intensity: 0.2,
            range: 1000
        });

        // add a white sphere to light so that we can see where it is. This sphere is excluded from the reflections.
        lightOmni.addComponent("render", {
            type: "sphere",
            layers: [excludedLayer.id],
            material: lightMaterial,
            castShadows: false,
            receiveShadows: false
        });
        lightOmni.setLocalScale(20, 20, 20);
        app.root.addChild(lightOmni);

        // create an Entity with a camera component
        const camera = new pc.Entity("MainCamera");
        camera.addComponent("camera", {
            fov: 100,
            layers: [worldLayer.id, excludedLayer.id, uiLayer.id],
            farClip: 1500
        });
        camera.setLocalPosition(270, 90, -260);

        // add orbit camera script with a mouse and a touch support
        camera.addComponent("script");
        camera.script.create("orbitCamera", {
            attributes: {
                inertiaFactor: 0.2,
                distanceMax: 390,
                frameOnStart: false
            }
        });
        camera.script.create("orbitCameraInputMouse");
        camera.script.create("orbitCameraInputTouch");
        app.root.addChild(camera);

        // create a probe object with cubemapRenderer script which takes care of rendering dynamic cubemap
        const probe = new pc.Entity('probeCamera');
        probe.addComponent('script');

        // add camera component to the probe - this defines camera properties for cubemap rendering
        probe.addComponent('camera', {

            // optimization - no need to clear as all pixels get overwritten
            clearColorBuffer: false,

            // priority - render before world camera
            priority: -1,

            // only render meshes on the worldLayer (and not excluded layer)
            layers: [worldLayer.id],

            // disable as this is not a camera that renders cube map but only a container for properties for cube map rendering
            enabled: false,

            nearClip: 1,
            farClip: 500
        });

        // Add a cubemap renderer script, which renders to a cubemap of size 128 with mipmaps, which is directly useable
        // as a lighting source for envAtlas generation
        // Position it in the center of the room.
        probe.script.create('cubemapRenderer', {
            attributes: {
                resolution: 128,
                mipmaps: true,
                depth: true
            }
        });
        probe.setPosition(0, 200, 0);
        app.root.addChild(probe);

        // handle onCubemapPostRender event fired by the cubemapRenderer when all faces of the cubemap are done rendering
        probe.on('onCubemapPostRender', () => {

            // prefilter just rendered cubemap into envAtlas, so that it can be used for reflection during the rest of the frame
            // @ts-ignore
            pc.EnvLighting.generateAtlas(probe.script.cubemapRenderer.cubeMap, {
                target: envAtlas
            });
        });

        // Set an update function on the app's update event
        let time = 0;
        let updateProbeCount = 1;
        let updateVideo = true;
        app.on("update", function (/** @type {number} */ dt) {
            time += dt * 0.3;

            // Update the video data to the texture every other frame
            if (updateVideo && videoTexture) {
                videoTexture.upload();
            }
            updateVideo = !updateVideo;

            // move the light around
            lightOmni.setLocalPosition(300 * Math.sin(time), 300, 300 * Math.cos(time));

            // update the reflection probe as needed
            const updateFrequency = data.get('settings.updateFrequency');
            updateProbeCount--;
            if (updateFrequency === 0)
                updateProbeCount = 1;

            if (updateProbeCount <= 0) {
                // enable probe rendering
                probe.enabled = true;
                updateProbeCount = updateFrequency;
            } else {
                probe.enabled = false;
            }

            // update material properties based on settings
            const gloss = data.get('settings.gloss');
            const metalness = data.get('settings.metalness');
            const bumpiness = data.get('settings.bumpiness');
            const reflectivity = data.get('settings.reflectivity');

            roomMaterial.gloss = gloss;
            roomMaterial.metalness = metalness;
            roomMaterial.bumpiness = bumpiness;
            roomMaterial.reflectivity = reflectivity;
            roomMaterial.update();

            sphereMaterial.gloss = gloss;
            sphereMaterial.metalness = metalness;
            sphereMaterial.bumpiness = bumpiness;
            sphereMaterial.reflectivity = reflectivity;
            sphereMaterial.update();
        });
    });
    return app;
}
        </script>
        <script>
        const ENGINE_PATH = '';
        const NODE_ENV = 'production';
        /**
         * Used in outline and posteffects to make ES5 scripts work in ES6
         * @example
         * // doesn't start with 'class', so not changing any behaviour
         * debugger; // step through with F11 to debug
         * Object.prototype.toString.call(1) === '[object Number]'
         */
        function enablePolyfillFunctionCall() {
            const functionCall = Function.prototype.call;
            function polyCall(thisArg, ...args) {
                if (this.toString().startsWith('class')) {
                    return Object.assign(thisArg, new this(...args));
                }
                return functionCall.bind(this)(thisArg, ...args);
            }
            Function.prototype.call = polyCall;
        }
        enablePolyfillFunctionCall();
        /**
         * Can load UMD and ESM. UMD registers itself into globalThis, while ESM is handled
         * to specifically to do the same, so we achieve the same result, no matter which
         * target build/src we linked to.
         */
        async function loadScript(name, src) {
            // console.log('loadScript>', { name, src });
            const module = await import(src);
            const isESM = Object.keys(module).length;
            if (isESM) {
                window[name] = module;
            }
        }
        /**
         * @returns {string}
         */
        function getDeviceType() {
            const last = localStorage.getItem('preferredGraphicsDevice');
            if (last !== null) {
                if (last === 'webgpu' && false) {
                    console.warn('Picked WebGPU but example is not supported on WebGPU, defaulting to WebGL2');
                    return 'webgl2';
                }
                return last;
            } else if (true) {
                let preferredDevice = 'webgpu';
                // Lack of Chrome's WebGPU support on Linux
                if (navigator.platform.includes('Linux') && navigator.appVersion.includes("Chrome")) {
                    preferredDevice = 'webgl2';
                }
                return window.top.preferredGraphicsDevice || preferredDevice;
            } else if (['webgl1', 'webgl2'].includes(window.top.preferredGraphicsDevice)) {
                return window.top.preferredGraphicsDevice;
            } else {
                return 'webgl2';
            }
        }
        /**
         * Get the specified engine, picking the right choice from three sources:
         *  - Example#ENGINE (lowest priority)
         *  - NODE_ENV (2nd lowest priority)
         *  - ENGINE_PATH (highest priority)
         * If none of these sources are given, we simply pick build/playcanvas.js (ES5)
         */
        function getSpecifiedEngine() {
            let specifiedEngine = './playcanvas.js';
            // Doesn't matter what Example class specifies otherwise, because
            // NODE_ENV has a higher priority
            if (NODE_ENV === 'development') {
                specifiedEngine = './playcanvas.dbg.js'
            }
            // ENGINE_PATH has the highest priority.
            if (ENGINE_PATH.length) {
                const entryPoint = ENGINE_PATH.split('/').pop();
                specifiedEngine = './ENGINE_PATH/' + entryPoint;
            }
            return specifiedEngine;
        }
        let ready = false; // Used in indicate if UI can render Controls
        let started = false;
        let miniStats;
        let allowRestart = 'true';
        const args = Object.fromEntries(
            location.href.split('?').pop().split('#')[0].split('&').map(_ => _.split('='))
        );
        let data = new observer.Observer({});
        /**
         * Keep it function in first run for nicer debug locations.
         * @type {Record<string, string | Function>}
         */
        const files = {};
        files['example.mjs'] = example.toString();
        if (window.controls) {
            files['controls.mjs'] = controls.toString();
        }
        var filesObject = {};
        function resolveFunction(_) {
            if (_.call) {
                return _;
            }
            return new Function('return ' + _)();
        }
        Object.assign(files, filesObject);
        function requestFiles() {
            const responseEvent = new CustomEvent("requestedFiles", { detail: files });
            window.top.dispatchEvent(responseEvent);
        }
        /**
         * This function is called from React whenever we click on MiniStats icon,
         * even PlayCanvas' pc itself could be undefined here.
         */
        function showStats() {
            // examples/misc/mini-stats.mjs creates its own instance of ministats, prevent two mini-stats here
            if (false) {
                return;
            }
            if (typeof pc === 'undefined' || typeof pcx === 'undefined') {
                return;
            }
            const { app } = pc;
            const deviceType = app?.graphicsDevice?.deviceType;
            if (deviceType === 'null') {
                return;
            }
            if (args.miniStats === 'false') {
                return;
            }
            if (!miniStats) {
                miniStats = new pcx.MiniStats(app);
            }
            miniStats.enabled = true;
        }
        function hideStats() {
            if (!miniStats) {
                return;
            }
            miniStats.enabled = false;
        }
        /**
         * This function is called from React whenever we change an example in any possible state,
         * even PlayCanvas' pc itself could be undefined here.
         */
        function destroy() {
            miniStats?.destroy();
            miniStats = null;
            // Can't call app.destroy() twice without an error,
            // so we check for app.graphicsDevice first
            const app = window.pc?.app;
            if (app && app.graphicsDevice) {
                app.destroy();
            }
            ready = false;
        }
        function hotReload() {
            if (!allowRestart) {
                console.warn('hotReload> Dropping restart while still restarting');
                return;
            }
            destroy();
            data = new observer.Observer({});
            main(files);
        }
        window.addEventListener('requestFiles', requestFiles);
        window.addEventListener('showStats'   , showStats   );
        window.addEventListener('hideStats'   , hideStats   );
        window.addEventListener('destroy'     , destroy     );
        window.addEventListener('hotReload'   , hotReload   );
        function updateControls() {
            const event = new CustomEvent("updateFiles", {
                detail: {
                    files
                }
            });
            window.top.dispatchEvent(event);
        }
        function updateActiveDevice() {
            const event = new CustomEvent("updateActiveDevice", {
                detail: pc.app.graphicsDevice.deviceType
            });
            window.top.dispatchEvent(event);
        }
        async function main(files) {
            allowRestart = false;
            await loadScript('pc', getSpecifiedEngine());
            await loadScript('pcx', './playcanvas-extras.js');
            window.top.pc = pc;
            var canvas = document.getElementById("application-canvas");
            window.top.observerData = data;
            var deviceType = getDeviceType();
            if (args.deviceType) {
                console.warn("overwriting default deviceType from URL");
                deviceType = args.deviceType;
            }
            if (!deviceType) {
                console.warn("No deviceType given, defaulting to WebGL2");
                deviceType = 'webgl2';
            }
            if (!started) {
                // console.log("Dispatch exampleLoading!");
                const event = new CustomEvent("exampleLoading"); // just notify to clean UI, but not during hot-reload
                window.top.dispatchEvent(event);
            }
            const example = resolveFunction(files['example.mjs']);
            files['example.mjs'] = files['example.mjs'].toString();
            const app = await example({
                canvas,
                deviceType,
                data,
                assetPath,
                scriptsPath,
                ammoPath,
                basisPath,
                dracoPath,
                glslangPath,
                twgslPath,
                pcx,
                files,
            });
            ready = true;
            class ExampleLoadEvent extends CustomEvent {
                constructor(deviceType) {
                    super("exampleLoad");
                    this.files = files;
                }
            }
            const finalFunc = () => {
                if (app.graphicsDevice?.canvas) {
                    showStats();
                    if (!started) { // only one time, recalls of main() are caused by Monaco live coding
                        window.top.dispatchEvent(new ExampleLoadEvent());
                    }
                    started = true;
                    updateControls();
                    updateActiveDevice();
                    allowRestart = true;
                } else {
                    console.warn('main> no canvas');
                }
            };
            // Wait until example has called app.start()
            // And if it already called start, we will know by app.frame > 0
            // app.start() is called when assets loaded in examples
            if (app.frame) { // app already started
                finalFunc();
            } else { // Wait for app.start()
                app.once('start', finalFunc);
            }
        }
        window.onload = () => main(files);
        </script>
    </body>
</html>